{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep_0-N_0MjIE",
        "outputId": "dc49379b-ab73-4f9f-9ae2-2699921e8054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.18.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_train = pd.read_csv ('/content/drive/MyDrive/dados_treino.csv') \n",
        "base_test = pd.read_csv ('/content/drive/MyDrive/dados_teste.csv') \n",
        "base_valid = pd.read_csv ('/content/drive/MyDrive/dados_validacao.csv') "
      ],
      "metadata": {
        "id": "TkhyrAWfQONz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "O_EHBIPjHCT6",
        "outputId": "7d65b3b4-bdb0-4281-f21e-cf49ba0662eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  name   category_1  \\\n",
              "0                    huge xxl tapestry         Home   \n",
              "1      small camo christmas tree skirt         Home   \n",
              "2                        dooney bourke        Women   \n",
              "3  be wild inspired by sauvage by dior       Beauty   \n",
              "4                    iphone plus cases  Electronics   \n",
              "\n",
              "                  category_2             category_3  item_condition_id  \\\n",
              "0                 Home Décor             Tapestries                  1   \n",
              "1             Seasonal Décor              Christmas                  2   \n",
              "2        Women's Accessories                Wallets                  1   \n",
              "3                  Fragrance                    Men                  1   \n",
              "4  Cell Phones & Accessories  Cases, Covers & Skins                  3   \n",
              "\n",
              "        brand_name  price  shipping  \\\n",
              "0         No Brand   23.0         1   \n",
              "1         No Brand    8.0         1   \n",
              "2  Dooney & Bourke   25.0         1   \n",
              "3         No Brand    8.0         1   \n",
              "4         No Brand   14.0         0   \n",
              "\n",
              "                                    item_description       date  stock  \n",
              "0  HUGE XXL BRAND NEW TAPESTRY 89\"by85\" Beautiful...  19-1-2018     49  \n",
              "1                         Small Christmas tree skirt   4-1-2018     17  \n",
              "2                                                New  17-6-2018      1  \n",
              "3  Diamond Collection's Be Wild 3.4 ounce large b...  16-8-2018     40  \n",
              "4  Love these speck cases! Great for iPhones. Ask...  30-7-2018      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5675871-c93a-490f-9d72-ed6f95ce47e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>category_1</th>\n",
              "      <th>category_2</th>\n",
              "      <th>category_3</th>\n",
              "      <th>item_condition_id</th>\n",
              "      <th>brand_name</th>\n",
              "      <th>price</th>\n",
              "      <th>shipping</th>\n",
              "      <th>item_description</th>\n",
              "      <th>date</th>\n",
              "      <th>stock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>huge xxl tapestry</td>\n",
              "      <td>Home</td>\n",
              "      <td>Home Décor</td>\n",
              "      <td>Tapestries</td>\n",
              "      <td>1</td>\n",
              "      <td>No Brand</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1</td>\n",
              "      <td>HUGE XXL BRAND NEW TAPESTRY 89\"by85\" Beautiful...</td>\n",
              "      <td>19-1-2018</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>small camo christmas tree skirt</td>\n",
              "      <td>Home</td>\n",
              "      <td>Seasonal Décor</td>\n",
              "      <td>Christmas</td>\n",
              "      <td>2</td>\n",
              "      <td>No Brand</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Small Christmas tree skirt</td>\n",
              "      <td>4-1-2018</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dooney bourke</td>\n",
              "      <td>Women</td>\n",
              "      <td>Women's Accessories</td>\n",
              "      <td>Wallets</td>\n",
              "      <td>1</td>\n",
              "      <td>Dooney &amp; Bourke</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1</td>\n",
              "      <td>New</td>\n",
              "      <td>17-6-2018</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>be wild inspired by sauvage by dior</td>\n",
              "      <td>Beauty</td>\n",
              "      <td>Fragrance</td>\n",
              "      <td>Men</td>\n",
              "      <td>1</td>\n",
              "      <td>No Brand</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1</td>\n",
              "      <td>Diamond Collection's Be Wild 3.4 ounce large b...</td>\n",
              "      <td>16-8-2018</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>iphone plus cases</td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Cell Phones &amp; Accessories</td>\n",
              "      <td>Cases, Covers &amp; Skins</td>\n",
              "      <td>3</td>\n",
              "      <td>No Brand</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Love these speck cases! Great for iPhones. Ask...</td>\n",
              "      <td>30-7-2018</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5675871-c93a-490f-9d72-ed6f95ce47e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5675871-c93a-490f-9d72-ed6f95ce47e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5675871-c93a-490f-9d72-ed6f95ce47e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# arquitetura do deep learning\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# ITEM CONDITION ID\n",
        "inp1 = layers.Input(shape=(1)) # INPUT 1 \n",
        "emb1  = layers.Embedding(6, 10, input_length=1)(inp1) # EMBEDDING 1\n",
        "flat1 = layers.Flatten()(emb1) # FLATTEN\n",
        "\n",
        "# SHIPPING \n",
        "inp2 = layers.Input(shape=(1)) # INPUT 2 \n",
        "d2 = layers.Dense(10, activation=\"relu\")(inp2) # DENSE LAYER 2\n",
        "\n",
        "# CATEGORY_1\n",
        "inp4 = layers.Input(shape=(3)) # INPUT 4\n",
        "emb4 = layers.Embedding(15, 16, input_length=3)(inp4) # EMBEDDING 4\n",
        "flat4 = layers.Flatten()(emb4) # FLATTEN \n",
        "\n",
        "# CATEGORY_2\n",
        "inp5= layers.Input(shape=(5)) # INPUT 5\n",
        "emb5 = layers.Embedding(146, 16, input_length=5)(inp5) # EMBEDDING 5\n",
        "flat5 = layers.Flatten()(emb5) # FLATTEN\n",
        "\n",
        "# CATEGORY_3\n",
        "inp6= layers.Input(shape=(7)) # INPUT 6 \n",
        "emb6 = layers.Embedding(963, 40 ,input_length=7)(inp6) # EMBEDDING 6\n",
        "flat6 = layers.Flatten()(emb6) # FLATTEN\n",
        "\n",
        "# ITEM_NAME_DESCRIPTION\n",
        "inp7= layers.Input(shape=(254)) # INPUT 7\n",
        "emb7 = layers.Embedding(152273, 20, input_length=254)(inp7) # EMBEDDING 7\n",
        "lstm7 = layers.GRU(64, return_sequences=True)(emb7) # GRU\n",
        "flat7 = layers.Flatten()(lstm7) # FLATTEN\n",
        "\n",
        "# CONCATENAÇÃO\n",
        "concat = layers.Concatenate()([flat1, d2, flat4, flat5, flat6, flat7])\n",
        "\n",
        "# DENSE LAYERS\n",
        "dense1 = layers.Dense(512, activation=\"relu\")(concat)\n",
        "\n",
        "# DROPOUT LAYER\n",
        "drop2 = layers.Dropout(0.2)(dense1)\n",
        "\n",
        "# DENSE LAYER\n",
        "dense2 = layers.Dense(256, activation=\"relu\")(drop2)\n",
        "\n",
        "# DROPOUT LAYER\n",
        "drop2 = layers.Dropout(0.2)(dense2)\n",
        "\n",
        "# DENSE LAYER\n",
        "dense3 = layers.Dense(128, activation=\"relu\")(drop2)\n",
        "\n",
        "# DROPOUT LAYER\n",
        "drop2 = layers.Dropout(0.2)(dense3)\n",
        "\n",
        "# BATCHNORM LAYER\n",
        "bn2  = layers.BatchNormalization()(drop2)\n",
        "\n",
        "# DENSE LAYER\n",
        "dense4 = layers.Dense(1, activation=\"linear\")(bn2)\n",
        "\n",
        "# MODEL\n",
        "model =  Model(inputs=[inp1, inp2, inp4, inp5, inp6, inp7], outputs=dense4)\n",
        "\n",
        "# SCHEDULE\n",
        "def shedule(epoch,lr):\n",
        "    if epoch<=2:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr*0.1\n",
        "\n",
        "# CALLBACKS\n",
        "lr = tf.keras.callbacks.LearningRateScheduler(shedule, verbose=1)\n",
        "save = tf.keras.callbacks.ModelCheckpoint(\".\",\n",
        "                                          monitor=\"val_root_mean_squared_error\",\n",
        "                                          mode=\"min\",\n",
        "                                          save_best_only=True,\n",
        "                                          save_weights_only=True,\n",
        "                                          verbose=1)\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(monitor=\"val_root_mean_squared_error\",\n",
        "                                             min_delta= 0.01, \n",
        "                                             patience=2,\n",
        "                                             mode=\"min\" )\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"mse\",\n",
        "              metrics=[tf.keras.losses.MeanAbsoluteError(), \n",
        "                       tfa.metrics.r_square.RSquare(),\n",
        "                       tf.keras.metrics.RootMeanSquaredError(), \n",
        "                       tf.keras.metrics.mean_absolute_percentage_error,\n",
        "                       tf.keras.metrics.mean_squared_logarithmic_error ])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sMoOFzcQUVB",
        "outputId": "622078a3-da7e-4efd-827e-b7469c1c9ac7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None, 215)]        0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, 3)]          0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None, 5)]          0           []                               \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 7)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, 215, 20)      3045460     ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1, 10)        60          ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 3, 16)        240         ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 5, 16)        2336        ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 7, 40)        38520       ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " gru (GRU)                      (None, 215, 64)      16512       ['embedding_4[0][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 10)           0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10)           20          ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 48)           0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 80)           0           ['embedding_2[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 280)          0           ['embedding_3[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)            (None, 13760)        0           ['gru[0][0]']                    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 14188)        0           ['flatten[0][0]',                \n",
            "                                                                  'dense[0][0]',                  \n",
            "                                                                  'flatten_1[0][0]',              \n",
            "                                                                  'flatten_2[0][0]',              \n",
            "                                                                  'flatten_3[0][0]',              \n",
            "                                                                  'flatten_4[0][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 512)          7264768     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 512)          0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 256)          131328      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 256)          0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 128)          32896       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 128)          0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 128)         512         ['dropout_2[0][0]']              \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 1)            129         ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,532,781\n",
            "Trainable params: 10,532,525\n",
            "Non-trainable params: 256\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PrepData():\n",
        "\n",
        "    def __init__(self,\n",
        "                 features=['category_1', 'category_2', 'category_3', 'name_brand_description'],\n",
        "                 max_lengths=[3, 5, 7, 215]):\n",
        "        self.features = features\n",
        "        self.max_lengths = max_lengths\n",
        "        self.tokenizers = {}\n",
        "        for feature in self.features:\n",
        "            self.tokenizers[feature] = Tokenizer()\n",
        "\n",
        "    def fillna(self, X):\n",
        "        X.item_description = X.item_description.fillna(\"No description\")\n",
        "        X.name = X.name.fillna(\"No name\")\n",
        "        return X\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        print('fitting_data')\n",
        "        X = self.fillna(X)\n",
        "        X['name_brand_description'] = self.brand_name_description(X)\n",
        "\n",
        "        for feature in self.features:\n",
        "            self.tokenizers[feature].fit_on_texts(X[feature].apply(str))\n",
        "        \n",
        "        print(feature)\n",
        "        print('data fitted')\n",
        "        return self\n",
        "    \n",
        "    def brand_name_description(self, X):\n",
        "      return X['name'] + ' ' + X['brand_name'] + \" \" + X['item_description']\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        print('transforming data')\n",
        "        item_condition = X.item_condition_id\n",
        "        shipping = X.shipping\n",
        "        output = [item_condition, shipping]\n",
        "        X = self.fillna(X)\n",
        "        X['name_brand_description'] = self.brand_name_description(X)\n",
        "\n",
        "        for i, feature in enumerate(self.features):\n",
        "            text_sequence = self.tokenizers[feature].texts_to_sequences(X[feature].apply(str))\n",
        "            pad = pad_sequences(text_sequence, padding='post', maxlen=self.max_lengths[i])\n",
        "            output.append(pad)\n",
        "        \n",
        "        print('data transformed')\n",
        "        \n",
        "        return output"
      ],
      "metadata": {
        "id": "MA2OR5IBQZJm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline(steps=[\n",
        "    ('tokenizer', PrepData()),\n",
        "    ('model', model)\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "rUsoxlskSoIO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline(steps=[\n",
        "    ('tokenizer', PrepData()),\n",
        "])"
      ],
      "metadata": {
        "id": "UIVm0iDFNeTy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.fit(base_train)"
      ],
      "metadata": {
        "id": "B_lBKcL_Ng2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans = pipe.transform(base_train)\n",
        "ans"
      ],
      "metadata": {
        "id": "NT4MWAKUNywE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ans[3]"
      ],
      "metadata": {
        "id": "T5CayiLlOJen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.fit(base_train, \n",
        "              np.log(base_train.price), \n",
        "              model__epochs=10,\n",
        "              model__batch_size=1024,\n",
        "              model__callbacks=[save, lr, earlystop])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqJxqv93SyTX",
        "outputId": "93d60a9a-19bb-4a3a-fc03-242de66ed5c8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fitting_data\n",
            "name_brand_description\n",
            "data fitted\n",
            "transforming data\n",
            "data transformed\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/10\n",
            "912/912 [==============================] - ETA: 0s - loss: 0.7263 - mean_absolute_error: 0.5557 - r_square: -0.1652 - root_mean_squared_error: 0.8522 - mean_absolute_percentage_error: 20.1754 - mean_squared_logarithmic_error: 0.0875"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_root_mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_root_mean_squared_error` which is not available. Available metrics are: loss,mean_absolute_error,r_square,root_mean_squared_error,mean_absolute_percentage_error,mean_squared_logarithmic_error,lr\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "912/912 [==============================] - 48s 44ms/step - loss: 0.7263 - mean_absolute_error: 0.5557 - r_square: -0.1652 - root_mean_squared_error: 0.8522 - mean_absolute_percentage_error: 20.1754 - mean_squared_logarithmic_error: 0.0875 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 2/10\n",
            "911/912 [============================>.] - ETA: 0s - loss: 0.2225 - mean_absolute_error: 0.3591 - r_square: 0.6430 - root_mean_squared_error: 0.4717 - mean_absolute_percentage_error: 13.4565 - mean_squared_logarithmic_error: 0.0152"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_root_mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_root_mean_squared_error` which is not available. Available metrics are: loss,mean_absolute_error,r_square,root_mean_squared_error,mean_absolute_percentage_error,mean_squared_logarithmic_error,lr\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "912/912 [==============================] - 40s 44ms/step - loss: 0.2225 - mean_absolute_error: 0.3591 - r_square: 0.6430 - root_mean_squared_error: 0.4717 - mean_absolute_percentage_error: 13.4564 - mean_squared_logarithmic_error: 0.0152 - lr: 0.0010\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 3/10\n",
            "912/912 [==============================] - ETA: 0s - loss: 0.1979 - mean_absolute_error: 0.3385 - r_square: 0.6825 - root_mean_squared_error: 0.4449 - mean_absolute_percentage_error: 12.6817 - mean_squared_logarithmic_error: 0.0136"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_root_mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_root_mean_squared_error` which is not available. Available metrics are: loss,mean_absolute_error,r_square,root_mean_squared_error,mean_absolute_percentage_error,mean_squared_logarithmic_error,lr\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "912/912 [==============================] - 41s 44ms/step - loss: 0.1979 - mean_absolute_error: 0.3385 - r_square: 0.6825 - root_mean_squared_error: 0.4449 - mean_absolute_percentage_error: 12.6817 - mean_squared_logarithmic_error: 0.0136 - lr: 0.0010\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.00010000000474974513.\n",
            "Epoch 4/10\n",
            "911/912 [============================>.] - ETA: 0s - loss: 0.1674 - mean_absolute_error: 0.3102 - r_square: 0.7315 - root_mean_squared_error: 0.4091 - mean_absolute_percentage_error: 11.6206 - mean_squared_logarithmic_error: 0.0116"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_root_mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_root_mean_squared_error` which is not available. Available metrics are: loss,mean_absolute_error,r_square,root_mean_squared_error,mean_absolute_percentage_error,mean_squared_logarithmic_error,lr\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "912/912 [==============================] - 40s 44ms/step - loss: 0.1674 - mean_absolute_error: 0.3102 - r_square: 0.7315 - root_mean_squared_error: 0.4091 - mean_absolute_percentage_error: 11.6206 - mean_squared_logarithmic_error: 0.0116 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 1.0000000474974514e-05.\n",
            "Epoch 5/10\n",
            "911/912 [============================>.] - ETA: 0s - loss: 0.1600 - mean_absolute_error: 0.3030 - r_square: 0.7433 - root_mean_squared_error: 0.4000 - mean_absolute_percentage_error: 11.3491 - mean_squared_logarithmic_error: 0.0111"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_root_mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_root_mean_squared_error` which is not available. Available metrics are: loss,mean_absolute_error,r_square,root_mean_squared_error,mean_absolute_percentage_error,mean_squared_logarithmic_error,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "912/912 [==============================] - 40s 44ms/step - loss: 0.1600 - mean_absolute_error: 0.3030 - r_square: 0.7433 - root_mean_squared_error: 0.4000 - mean_absolute_percentage_error: 11.3488 - mean_squared_logarithmic_error: 0.0111 - lr: 1.0000e-05\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 1.0000000656873453e-06.\n",
            "Epoch 6/10\n",
            "912/912 [==============================] - ETA: 0s - loss: 0.1587 - mean_absolute_error: 0.3021 - r_square: 0.7455 - root_mean_squared_error: 0.3983 - mean_absolute_percentage_error: 11.3241 - mean_squared_logarithmic_error: 0.0111"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_root_mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_root_mean_squared_error` which is not available. Available metrics are: loss,mean_absolute_error,r_square,root_mean_squared_error,mean_absolute_percentage_error,mean_squared_logarithmic_error,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r912/912 [==============================] - 41s 45ms/step - loss: 0.1587 - mean_absolute_error: 0.3021 - r_square: 0.7455 - root_mean_squared_error: 0.3983 - mean_absolute_percentage_error: 11.3241 - mean_squared_logarithmic_error: 0.0111 - lr: 1.0000e-06\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 1.0000001111620805e-07.\n",
            "Epoch 7/10\n",
            "911/912 [============================>.] - ETA: 0s - loss: 0.1587 - mean_absolute_error: 0.3021 - r_square: 0.7453 - root_mean_squared_error: 0.3984 - mean_absolute_percentage_error: 11.3217 - mean_squared_logarithmic_error: 0.0111"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_root_mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_root_mean_squared_error` which is not available. Available metrics are: loss,mean_absolute_error,r_square,root_mean_squared_error,mean_absolute_percentage_error,mean_squared_logarithmic_error,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r912/912 [==============================] - 41s 45ms/step - loss: 0.1587 - mean_absolute_error: 0.3021 - r_square: 0.7454 - root_mean_squared_error: 0.3984 - mean_absolute_percentage_error: 11.3218 - mean_squared_logarithmic_error: 0.0111 - lr: 1.0000e-07\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 1.000000082740371e-08.\n",
            "Epoch 8/10\n",
            "911/912 [============================>.] - ETA: 0s - loss: 0.1588 - mean_absolute_error: 0.3021 - r_square: 0.7452 - root_mean_squared_error: 0.3985 - mean_absolute_percentage_error: 11.3257 - mean_squared_logarithmic_error: 0.0111"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_root_mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_root_mean_squared_error` which is not available. Available metrics are: loss,mean_absolute_error,r_square,root_mean_squared_error,mean_absolute_percentage_error,mean_squared_logarithmic_error,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r912/912 [==============================] - 41s 45ms/step - loss: 0.1588 - mean_absolute_error: 0.3021 - r_square: 0.7452 - root_mean_squared_error: 0.3985 - mean_absolute_percentage_error: 11.3253 - mean_squared_logarithmic_error: 0.0111 - lr: 1.0000e-08\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 1.000000082740371e-09.\n",
            "Epoch 9/10\n",
            "912/912 [==============================] - ETA: 0s - loss: 0.1587 - mean_absolute_error: 0.3021 - r_square: 0.7454 - root_mean_squared_error: 0.3984 - mean_absolute_percentage_error: 11.3215 - mean_squared_logarithmic_error: 0.0111"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_root_mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_root_mean_squared_error` which is not available. Available metrics are: loss,mean_absolute_error,r_square,root_mean_squared_error,mean_absolute_percentage_error,mean_squared_logarithmic_error,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r912/912 [==============================] - 40s 44ms/step - loss: 0.1587 - mean_absolute_error: 0.3021 - r_square: 0.7454 - root_mean_squared_error: 0.3984 - mean_absolute_percentage_error: 11.3215 - mean_squared_logarithmic_error: 0.0111 - lr: 1.0000e-09\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 1.000000082740371e-10.\n",
            "Epoch 10/10\n",
            "912/912 [==============================] - ETA: 0s - loss: 0.1591 - mean_absolute_error: 0.3021 - r_square: 0.7447 - root_mean_squared_error: 0.3989 - mean_absolute_percentage_error: 11.3224 - mean_squared_logarithmic_error: 0.0111"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_root_mean_squared_error available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_root_mean_squared_error` which is not available. Available metrics are: loss,mean_absolute_error,r_square,root_mean_squared_error,mean_absolute_percentage_error,mean_squared_logarithmic_error,lr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r912/912 [==============================] - 40s 44ms/step - loss: 0.1591 - mean_absolute_error: 0.3021 - r_square: 0.7447 - root_mean_squared_error: 0.3989 - mean_absolute_percentage_error: 11.3224 - mean_squared_logarithmic_error: 0.0111 - lr: 1.0000e-10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tokenizer', <__main__.PrepData object at 0x7f6f0012cf90>),\n",
              "                ('model',\n",
              "                 <keras.engine.functional.Functional object at 0x7f6f00043950>)])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando o modelo"
      ],
      "metadata": {
        "id": "zxy1U5sNugpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_avaliacao(obs, pred):\n",
        "    print('R² = %.3f' % metrics.r2_score(obs, pred))\n",
        "    print('MAPE = %.3f %%' % (100 * metrics.mean_absolute_percentage_error(obs, pred)))\n",
        "    print('MAE = U$S %.2f' % (metrics.mean_absolute_error(obs, pred)))\n",
        "    print('RMSE = U$S %.2f' % metrics.mean_squared_error(obs, pred)**0.5)\n",
        "    print('RMSLE = %.4f' % metrics.mean_squared_log_error(obs, pred,squared=False))"
      ],
      "metadata": {
        "id": "cXnlKbfzuwyo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2 = np.exp(pipe.predict(base_train))\n",
        "\n",
        "#print_avaliacao(base_train.price, y_pred2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9toaj_Ex1uDr",
        "outputId": "15fa2a1a-7b09-4f07-81aa-781eff07adaa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transforming data\n",
            "29171/29171 [==============================] - 144s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_avaliacao(base_train.price, y_pred2)"
      ],
      "metadata": {
        "id": "T1VCaXTkQe2z",
        "outputId": "2addcbd0-4706-4e6f-e575-fafa9636184b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² = 0.653\n",
            "MAPE = 30.579 %\n",
            "MAE = U$S 8.10\n",
            "RMSE = U$S 22.73\n",
            "RMSLE = 0.3616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2 = np.exp(pipe.predict(base_test))\n",
        "\n",
        "print_avaliacao(base_test.price, y_pred2)"
      ],
      "metadata": {
        "id": "-9Rf7Y5Yuzom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50c6f89b-31dd-4848-ffae-3c4c6140588a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transforming data\n",
            "data transformed\n",
            "12502/12502 [==============================] - 62s 5ms/step\n",
            "R² = 0.537\n",
            "MAPE = 37.351 %\n",
            "MAE = U$S 9.74\n",
            "RMSE = U$S 26.34\n",
            "RMSLE = 0.4348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salvando os dumps do modelo."
      ],
      "metadata": {
        "id": "sx9_82wVudI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "rnn = pipe['model']\n",
        "rnn.save('rnn_keras.h5') # salva somente a rnn\n",
        "pipe.steps[1] = ('model', None) # remove modelo da pipeline pq o pickle não funciona com keras\n",
        "\n",
        "\n",
        "#Faz o dump do pipeline\n",
        "with open(f'pipeline.pickle', 'wb') as handle:\n",
        "  pickle.dump(pipe, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "OGT7awIwTBuF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando o modelo a partir dos dumps salvos"
      ],
      "metadata": {
        "id": "skJnM2PbuMn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Carrega o rnn\n",
        "modelo_lido = keras.models.load_model('rnn_keras.h5', compile=False)\n",
        "\n",
        "# Carrega a pipeline\n",
        "with open(f'pipeline.pickle', 'rb') as handle:\n",
        "  nova_pipeline = pickle.load(handle)\n",
        "\n",
        "# Adiciona a rnn a nova pipeline\n",
        "nova_pipeline.steps[1] = ('model', modelo_lido)"
      ],
      "metadata": {
        "id": "vVAPoohAuGig"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testando o modelo carregado a partir dos dumps"
      ],
      "metadata": {
        "id": "4o8wszfvurjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_test.shape, base_test.dropna().shape"
      ],
      "metadata": {
        "id": "kg3gaU5uveqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2 = np.exp(nova_pipeline.predict(base_test))\n",
        "print_avaliacao(base_test.price, y_pred2)\n"
      ],
      "metadata": {
        "id": "g9uXpMV-uulD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f96d834-0a52-4656-cf7f-f8e6dcb42f45"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transforming data\n",
            "data transformed\n",
            "12502/12502 [==============================] - 61s 5ms/step\n",
            "R² = 0.537\n",
            "MAPE = 37.351 %\n",
            "MAE = U$S 9.74\n",
            "RMSE = U$S 26.34\n",
            "RMSLE = 0.4348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O script final necessita ter a class PrepData para poder executar o modelo."
      ],
      "metadata": {
        "id": "DZ6Dv_qLuVzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(y_pred2[np.where(y_pred2 == y_pred2.max())])"
      ],
      "metadata": {
        "id": "AV6mDUhIuTHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JnMfC0FpxYaA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}